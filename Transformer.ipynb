{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c283586",
   "metadata": {},
   "source": [
    "# Attention is All You Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809f5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2ff9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_layer(layer, n): \n",
    "    '''Function to create n copies of a layer'''\n",
    "    return nn.ModuleList([copy.deepcopy(layer) for _ in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd53fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_mask(n):\n",
    "    mask = torch.ones(1,n,n)\n",
    "    mask = torch.tril(mask, diagonal=-1)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50738f8",
   "metadata": {},
   "source": [
    "### Attention Mechanism\n",
    "\n",
    "<img style=\"float: left;\" src=\"artifacts/attention.png\" height=480 width=480>\n",
    "<img style=\"float: right;\" src=\"artifacts/scaled dot-product attention.png\" height=280 width=280>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f683a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, d_model, d_k, d_v):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "        \n",
    "        self.query = nn.Linear(d_model, d_k)\n",
    "        self.key = nn.Linear(d_model, d_k)\n",
    "        self.value = nn.Linear(d_model, d_v)\n",
    "    \n",
    "    def forward(self, q, k ,v, mask=None):\n",
    "        Q = self.query(q)\n",
    "        K = self.key(k)\n",
    "        V = self.value(v)\n",
    "        \n",
    "        attn_wt = (torch.matmul(Q, K.transpose(-2, -1)))/(self.d_k**0.5)\n",
    "        \n",
    "        if mask is not None:\n",
    "            attn_wt.masked_fill_(mask==0, -1e9)\n",
    "            \n",
    "        score = F.softmax(attn_wt, dim=-1)\n",
    "        \n",
    "        attention = torch.matmul(score, V)\n",
    "        \n",
    "        return attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9edbf",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"artifacts/Multi Head attention form.png\" height=480 width=480>\n",
    "<img style=\"float: right;\" src=\"artifacts/Multi head attention.png\" height=280 width=280>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158034c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.h = heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.d_v = d_model // heads\n",
    "    \n",
    "        self.attns = clone_layer(AttentionHead(d_model, self.d_k, self.d_k), self.h)\n",
    "        \n",
    "        self.multi_head_out = nn.Linear(heads*self.d_v, d_model)\n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        heads = [attn(q, k, v, mask) for attn in self.attns]  #(head1,...,head_h)\n",
    "        \n",
    "        concat_heads = torch.concat(heads, dim=-1)            #Concat(heads)\n",
    "        \n",
    "        return self.multi_head_out(concat_heads)              #Linear(Concatenated heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54d7aa",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "<img src=\"artifacts/Encoder.png\" height=280 width=280>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344f71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, attn_heads, d_ff, dropout=0.1):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.multi_head_attn  = MultiHeadAttention(attn_heads, d_model)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        attn_out = self.dropout(self.multi_head_attn(x,x,x, mask))  #Multi head Attention\n",
    "        add_norm1 = self.layer_norm1(x+attn_out)                    #Add & Norm\n",
    "        \n",
    "        ff_out = self.dropout(self.ffn(add_norm1))                  #Feed Forward\n",
    "        add_norm2 = self.layer_norm1(add_norm1+ff_out)              #Add & Norm\n",
    "        \n",
    "        return add_norm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab2854f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''Creates a stack of Encoder Blocks of size num_layers'''\n",
    "    def __init__(self, num_layers, d_model, attn_heads, d_ff, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.encoders = clone_layer(EncoderBlock(d_model, attn_heads, d_ff, dropout), num_layers)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.encoders:\n",
    "            x = layer(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03104b37",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "<img src=\"artifacts/Decoder.png\" height=280 width=280>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9d7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, attn_heads, d_ff, dropout=0.1):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        \n",
    "        self.masked_multi_head_attn  = MultiHeadAttention(attn_heads, d_model)\n",
    "        self.multi_head_attn  = MultiHeadAttention(attn_heads, d_model)\n",
    "        \n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm3 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, encd_out, mask):\n",
    "        masked_attn_out = self.dropout1(self.masked_multi_head_attn(x,x,x, mask))      #Masked Multi-Head Attention\n",
    "        add_norm1 = self.layer_norm1(x+masked_attn_out)                               #Add & Norm\n",
    "        \n",
    "        attn_out = self.dropout2(self.multi_head_attn(add_norm1, encd_out, encd_out))  #Encoder-Decoder Multi-Head Attention\n",
    "        add_norm2 = self.layer_norm2(add_norm1+attn_out)                              #Add & Norm\n",
    "        \n",
    "        ff_out = self.dropout3(self.ffn(add_norm2))                                    #Feed Forward\n",
    "        add_norm3 = self.layer_norm1(add_norm2+ff_out)                                #Add & Norm\n",
    "        \n",
    "        return add_norm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9199cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    '''Creates a stack of Decoder Blocks of size num_layers'''\n",
    "    def __init__(self, num_layers, d_model, attn_heads, d_ff, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoders = clone_layer(DecoderBlock(d_model, attn_heads, d_ff, dropout), num_layers)\n",
    "        \n",
    "    def forward(self, x, encdr_out, mask=None):\n",
    "        for layer in self.decoders:\n",
    "            x = layer(x, encdr_out, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01a3a89",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "<img style=\"float: left;\" src=\"artifacts/positional encoding.png\" height=380 width=380>\n",
    "<img style=\"float: right;\" src=\"artifacts/Encoding.png\" height=380 width=380>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e430e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5_000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        pos_encd = torch.empty(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        \n",
    "        denom = torch.exp(torch.arange(0, d_model, 2)*-(math.log(1000))/d_model)\n",
    "        \n",
    "        pos_encd[:, 0::2] = torch.sin(position*denom)\n",
    "        pos_encd[:, 1::2] = torch.cos(position*denom)\n",
    "        \n",
    "        pos_encd = pos_encd.unsqueeze(0)\n",
    "        \n",
    "        self.register_buffer(\"pos_encd\", pos_encd) #to include it in the models state dict and also to push it on the same device as the model which uses it\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x+self.pos_encd[:, :x.shape[1]].requires_grad_(False)\n",
    "        return self.dropout(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d483f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(InputEmbedding, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.embed(x)\n",
    "        return out/(self.d_model**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2507d9",
   "metadata": {},
   "source": [
    "### Complete Transformer\n",
    "<img src=\"artifacts/Transformer.png\" height=380 width=380>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91cf4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, trgt_vocab, nheads=8,num_encoder_layers=6, num_decoder_layers=6, d_ff=2048, dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.encoders = Encoder(num_encoder_layers, d_model, nheads, d_ff, dropout)\n",
    "        self.decoders = Decoder(num_decoder_layers, d_model, nheads, d_ff, dropout)\n",
    "        \n",
    "        self.encoder_pos = PositionalEncoding(d_model, dropout)\n",
    "        self.decoder_pos = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        self.out = nn.Linear(d_model, trgt_vocab)\n",
    "    \n",
    "    def forward(self, src, trgt, trgt_mask, src_mask=None):\n",
    "        encdr_inp = self.encoder_pos(src)\n",
    "        dcdr_inp = self.decoder_pos(trgt)\n",
    "        \n",
    "        encdr_out = self.encoders(encdr_inp, src_mask)\n",
    "        decoder_out = self.decoders(dcdr_inp, encdr_out, trgt_mask)\n",
    "        \n",
    "        out = self.out(decoder_out)\n",
    "        return F.log_softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "565fabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e59d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.randn(5, 10, d_model)\n",
    "trgt = torch.randn(5, 12, d_model)\n",
    "trgt_mask = generate_target_mask(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd7688a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trnsfrmr = Transformer(d_model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92b1076f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 10, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 12])\n",
      "value shape:  torch.Size([5, 12, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n",
      "Score shape:  torch.Size([5, 12, 10])\n",
      "value shape:  torch.Size([5, 10, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 12, 20])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = trnsfrmr(src, trgt, trgt_mask)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aadcbc",
   "metadata": {},
   "source": [
    "<b>Note</b>: `source` and `target embedding size` should be same as `d_model`. Both these embeddings could be trained using `InputEmbedding` or we canuse pretrained embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215716ec",
   "metadata": {},
   "source": [
    "Refernce: [Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
